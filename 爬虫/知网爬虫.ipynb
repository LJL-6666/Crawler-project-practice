{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:53:21.800141Z",
     "start_time": "2020-08-28T09:53:21.076737Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests #爬取IP端口和\n",
    "from bs4 import BeautifulSoup as bs #bs4解析库，用来解析网页\n",
    "import time\n",
    "import openpyxl #对Excel的操作\n",
    "import re   #对字符串的操作\n",
    "import xlrd #xls文件的读\n",
    "import xlwt #xls文件的写\n",
    "from xlutils.copy import copy#修改（追加写入）\n",
    "from my_fake_useragent import UserAgent #这个库用来做反爬虫的\n",
    "#这库用来随机生成user_agent 在这个爬虫中好像没必要 一样会循环重定向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:59:55.699067Z",
     "start_time": "2020-08-28T09:59:55.692085Z"
    }
   },
   "outputs": [],
   "source": [
    "def pagenext():\n",
    "    #最开始的链接 最后面 'p=' 添加你要的页数 就能去其他页\n",
    "    base_url = 'http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p='\n",
    "    L = range(0, 450) #修改这里可以改变获取的数量 不要太多 不然跑很久    4500就是300页了\n",
    "    # All_Page = []\n",
    "    for i in L[::15]: #15条是一页\n",
    "        All_Page = []\n",
    "        next_url = base_url + str(i)#配置下一页的url，每15个数据一页\n",
    "        print(next_url)\n",
    "        print(i / 15 + 1, \" 页的数据\")\n",
    "        page_text = spider(next_url)      #跑第*页的爬虫 获取那一页的数据\n",
    "        time.sleep(10)        #休息一会 防被网站 ban\n",
    "        write_excel('G:/CDO/知网研学/CNKI-analysis-master/区块链论文筛选.xls',i / 15 + 1, page_text)  #写进Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:54:51.002463Z",
     "start_time": "2020-08-28T09:54:50.989490Z"
    }
   },
   "outputs": [],
   "source": [
    "#进入了文章的具体ulr\n",
    "def datespider(date_url):\n",
    "    #设置一下 UserAgent 突破反扒\n",
    "    response_try = requests.get(date_url, UserAgent().random())\n",
    "    # 用BeautifulSoup框架转化\n",
    "    response_tree = bs(response_try.text, 'html.parser')\n",
    "    if(response_tree==None):\n",
    "        return []\n",
    "    else:\n",
    "        # 在对应位置 匹配需要的信息\n",
    "        res_date = response_tree.find(\"font\", {\"color\": \"#0080ff\"})\n",
    "        res_name = response_tree.find(\"div\", {\"style\": \"text-align:center; width:740px; height:30px;\"})\n",
    "        res_msg = response_tree.find(\"div\", {\"style\": \"text-align:left;\"})\n",
    "\n",
    "        #时间\n",
    "        if res_date == None:\n",
    "            response_date = None\n",
    "        else:\n",
    "            response_date = res_date.get_text().replace('\\xa0', '').replace('\\r', '').replace('\\n', '').replace('\\t', '')\n",
    "        #作者\n",
    "        if res_name == None:\n",
    "            response_name = None\n",
    "        else:\n",
    "            response_name = res_name.get_text().replace('\\xa0', '').replace('\\r', '').replace('\\n', '').replace('\\t', '')\n",
    "        #其他信息\n",
    "        if res_msg == None:\n",
    "            res_msg = None\n",
    "        else:\n",
    "            # 去除不想要的东西\n",
    "            response_msg = res_msg.get_text().replace('\\xa0', '').replace('\\r', '').replace('\\n', '').replace('\\t','')\\\n",
    "                .replace('】', '').replace('学位授予单位：', '').replace('学位级别：', '').replace('作者单位：', '').replace('学位授予年份：','').replace('分类号：', '')\n",
    "            #用“【”作为分割界限，将response_msg字符串 划分为 response_point列表\n",
    "            response_point = response_msg.split(\"【\")\n",
    "        #插入列表 并返回\n",
    "        response_All = []\n",
    "        response_All.append(response_date)\n",
    "        response_All.append(response_name)\n",
    "        #列表拼接\n",
    "        #列表拼接\n",
    "        for item in range(1,len(response_point)):\n",
    "            response_All.append(response_point[item])\n",
    "\n",
    "        return response_All  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:55:06.544096Z",
     "start_time": "2020-08-28T09:55:06.537117Z"
    }
   },
   "outputs": [],
   "source": [
    "#写进表格里面去\n",
    "def write_excel(path, page, text_info):\n",
    "\n",
    "    index = len(text_info)\n",
    "    # workbook = openpyxl.Workbook()\n",
    "    workbook = xlrd.open_workbook(path)#打开\n",
    "    sheets = workbook.sheet_names()\n",
    "    sheet = workbook.sheet_by_name(sheets[0])  # 获取工作簿中所有表格中的的第一个表格\n",
    "    rows_old = sheet.nrows  # 获取表格中已存在的数据的行数\n",
    "    new_workbook = copy(workbook)  # 将xlrd对象拷贝转化为xlwt对象\n",
    "    new_worksheet = new_workbook.get_sheet(0)  # 获取转化后工作簿中的第一个表格\n",
    "    # sheet.title = sheet_name\n",
    "    for i in range(0, index):\n",
    "        for j in range(len(text_info[i])):\n",
    "            new_worksheet.write(i + rows_old,j,str(text_info[i][j]))\n",
    "    new_workbook.save(path)\n",
    "\n",
    "    print(page,\" 页写入数据成功！\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:55:37.951976Z",
     "start_time": "2020-08-28T09:55:37.940011Z"
    }
   },
   "outputs": [],
   "source": [
    "def spider(url):\n",
    "    response = requests.get(url, {'User-Agent':UserAgent().random()})#用来突破反爬虫\n",
    "    res = response.content\n",
    "    html = str(res, 'utf-8')#用来获取html页面\n",
    "    html_tree = bs(html, 'lxml')\n",
    "    # 找class = wz_content标签下的内容\n",
    "    html_text = html_tree.find_all(\"div\", class_=\"wz_content\")\n",
    "    All_text = []\n",
    "    for text in html_text:\n",
    "        one_text = []\n",
    "        text_url = text.find('a')['href']  # 选取了当前文章的链接\n",
    "        text_title = text.find('h3') #标题\n",
    "        text_cout = text.find(\"span\", class_=\"count\")\n",
    "        #舍弃http://youxian.cnki链接 打不开的 没数据 可能需要登陆才有数据 之后再调试吧  出现概率1/20\n",
    "        if re.match(r'http://www.cnki.com.cn/Article/[a-zA-Z]+-[0-9a-zA-Z-]+.htm', text_url) or re.match(r'http://cdmd.cnki.com.cn/Article/[a-zA-Z]+-[0-9a-zA-Z-]+.htm', text_url):\n",
    "            # 调用函数 进去各个文章的具体网站 找其他信息\n",
    "            text_all = datespider(text_url)\n",
    "            one_text.append(text_title.get_text().replace('\\xa0', '').replace('\\n', ''))  # 得到文章的标题\n",
    "            one_text.append(text_cout.get_text().replace('\\xa0', '').replace('\\n', '').replace('下载次数', '').replace('被引次数', '').replace('（', '').replace('）', ''))  # 把操作次数 放进列表\n",
    "            for item in text_all:#将datespider函数返回的信息，文章的 作者、单位、学位 、分类号，插入列表\n",
    "                one_text.append(item.replace('\\t', '').replace('\\r', '').replace('\\n', '').replace(' ', '').replace('年', ''))\n",
    "            one_text.append(text_url)  # 把文章的链接 放进列表\n",
    "\n",
    "            All_text.append(one_text)\n",
    "    return All_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:09:49.982250Z",
     "start_time": "2020-08-28T10:04:03.142743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=0\n",
      "1.0  页的数据\n",
      "1.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=15\n",
      "2.0  页的数据\n",
      "2.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=30\n",
      "3.0  页的数据\n",
      "3.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=45\n",
      "4.0  页的数据\n",
      "4.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=60\n",
      "5.0  页的数据\n",
      "5.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=75\n",
      "6.0  页的数据\n",
      "6.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=90\n",
      "7.0  页的数据\n",
      "7.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=105\n",
      "8.0  页的数据\n",
      "8.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=120\n",
      "9.0  页的数据\n",
      "9.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=135\n",
      "10.0  页的数据\n",
      "10.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=150\n",
      "11.0  页的数据\n",
      "11.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=165\n",
      "12.0  页的数据\n",
      "12.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=180\n",
      "13.0  页的数据\n",
      "13.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=195\n",
      "14.0  页的数据\n",
      "14.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=210\n",
      "15.0  页的数据\n",
      "15.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=225\n",
      "16.0  页的数据\n",
      "16.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=240\n",
      "17.0  页的数据\n",
      "17.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=255\n",
      "18.0  页的数据\n",
      "18.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=270\n",
      "19.0  页的数据\n",
      "19.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=285\n",
      "20.0  页的数据\n",
      "20.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=300\n",
      "21.0  页的数据\n",
      "21.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=315\n",
      "22.0  页的数据\n",
      "22.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=330\n",
      "23.0  页的数据\n",
      "23.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=345\n",
      "24.0  页的数据\n",
      "24.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=360\n",
      "25.0  页的数据\n",
      "25.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=375\n",
      "26.0  页的数据\n",
      "26.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=390\n",
      "27.0  页的数据\n",
      "27.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=405\n",
      "28.0  页的数据\n",
      "28.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=420\n",
      "29.0  页的数据\n",
      "29.0  页写入数据成功！\n",
      "http://search.cnki.com.cn/Search.aspx?q=%e5%8c%ba%e5%9d%97%e9%93%be&rank=relevant&cluster=all&val=&p=435\n",
      "30.0  页的数据\n",
      "30.0  页写入数据成功！\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pagenext() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:15:06.497895Z",
     "start_time": "2020-08-28T10:15:06.492908Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import xlwt\n",
    "import openpyxl\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:17:30.499145Z",
     "start_time": "2020-08-28T10:17:30.444293Z"
    }
   },
   "outputs": [],
   "source": [
    "def pagenext():\n",
    "    base_url = 'http://search.cnki.com.cn/search.aspx?q=%E6%96%B0%E9%97%BB%E4%BC%A0%E6%92%AD&rank=relevant&cluster=Type&val=I141&p='\n",
    "    L = range(0, 840)  # 最尾巴的数不计入\n",
    "    All_Page = []\n",
    "    for i in L[::10]:\n",
    "        next_url = base_url + str(i)\n",
    "        # print(next_url)\n",
    "        print(\"第 \", i / 10 + 1, \" 页的数据\")\n",
    "        page_text = spider(next_url)\n",
    "        time.sleep(10)\n",
    "        for page in page_text:\n",
    "            All_Page.append(page)\n",
    "    print(All_Page)\n",
    "    write_excel('G:/CDO/知网研学/CNKI-analysis-master/区块链知网论文.XLSX', 'info', All_Page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:17:47.796632Z",
     "start_time": "2020-08-28T10:17:47.788660Z"
    }
   },
   "outputs": [],
   "source": [
    "def datespider(date_url):\n",
    "    # 因为跳转的链接类型不一样，所以我们要判断这两种链接是哪一种并且选择不一样的解析find方法\n",
    "    response_try = requests.get(date_url, {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36'})\n",
    "    # print(response_try.text)\n",
    "    response_tree = bs(response_try.text, 'html.parser')\n",
    "    # 根据两个不同的链接返回不一样的值\n",
    "    if re.match(r'http://www.cnki.com.cn/Article/[0-9a-zA-Z\\_]+', date_url):\n",
    "        res_date = response_tree.find(\"font\", {\"color\": \"#0080ff\"})\n",
    "        if res_date == None:\n",
    "            response_date = None\n",
    "        else:\n",
    "            response_date = res_date.get_text().replace('\\r', '').replace('\\n', '')\n",
    "    else:\n",
    "        response_date = response_tree.find(\"title\").get_text()[-8:]\n",
    "    return response_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:17:58.044059Z",
     "start_time": "2020-08-28T10:17:58.037078Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_excel(path, sheet_name, text_info):\n",
    "    index = len(text_info)\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "    for i in range(0, index):\n",
    "        for j in range(len(text_info[i])):\n",
    "            sheet.cell(row=i + 1, column=j + 1, value=str(text_info[i][j]))\n",
    "    workbook.save(path)\n",
    "    print(\"xlsx格式表格写入数据成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:39:15.437980Z",
     "start_time": "2020-08-28T10:39:15.421059Z"
    }
   },
   "outputs": [],
   "source": [
    "def spider(url):\n",
    "    response = requests.get(url, {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36'})\n",
    "    res = response.content\n",
    "    html = str(res, 'utf-8')\n",
    "    html_tree = bs(html, 'lxml')\n",
    "    # 找打h3标签下的内容\n",
    "    html_text = html_tree.find_all(\"h3\")\n",
    "    All_text = []\n",
    "    # 隔一个才是文章的标题\n",
    "    for text in html_text[1:-2:]:\n",
    "        one_text = []\n",
    "        text_title = text.get_text().replace('\\xa0', '').replace('\\n', '')  # 得到论文的标题\n",
    "        # print(text.get_text())\n",
    "        text_url = text.find('a')['href']  # 选取了当前文章的链接\n",
    "        # 用正则表达式匹配我们需要的链接\n",
    "        if re.match(r\"\"\"http://youxian.cnki.com.cn/yxdetail.aspx\\?filename=[0-9a-zA-Z]+&dbname=[a-zA-Z]+\"\"\",\n",
    "                    text_url) or re.match(r'http://www.cnki.com.cn/Article/[a-zA-Z]+-[0-9a-zA-Z-]+.htm', text_url):\n",
    "            # print(text.find('a')['href'])\n",
    "            text_date = datespider(text_url)\n",
    "            one_text.append(text.get_text().replace('\\xa0', '').replace('\\n', ''))  # text.get_text是得到文章的标题\n",
    "            if text_date == None:\n",
    "                one_text.append(None)\n",
    "            else:\n",
    "                if int(text_date[:4]) >= 2014:\n",
    "                    one_text.append(text_date.replace('\\t', '').replace('\\r', '').replace('\\n', '').replace(' ', ''))\n",
    "                else:\n",
    "                    continue\n",
    "            All_text.append(one_text)\n",
    "    # print(text.find('a')['href'])\n",
    "\n",
    "    # print(All_text)\n",
    "    return All_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T10:35:23.998203Z",
     "start_time": "2020-08-28T10:18:35.877080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第  1.0  页的数据\n",
      "第  2.0  页的数据\n",
      "第  3.0  页的数据\n",
      "第  4.0  页的数据\n",
      "第  5.0  页的数据\n",
      "第  6.0  页的数据\n",
      "第  7.0  页的数据\n",
      "第  8.0  页的数据\n",
      "第  9.0  页的数据\n",
      "第  10.0  页的数据\n",
      "第  11.0  页的数据\n",
      "第  12.0  页的数据\n",
      "第  13.0  页的数据\n",
      "第  14.0  页的数据\n",
      "第  15.0  页的数据\n",
      "第  16.0  页的数据\n",
      "第  17.0  页的数据\n",
      "第  18.0  页的数据\n",
      "第  19.0  页的数据\n",
      "第  20.0  页的数据\n",
      "第  21.0  页的数据\n",
      "第  22.0  页的数据\n",
      "第  23.0  页的数据\n",
      "第  24.0  页的数据\n",
      "第  25.0  页的数据\n",
      "第  26.0  页的数据\n",
      "第  27.0  页的数据\n",
      "第  28.0  页的数据\n",
      "第  29.0  页的数据\n",
      "第  30.0  页的数据\n",
      "第  31.0  页的数据\n",
      "第  32.0  页的数据\n",
      "第  33.0  页的数据\n",
      "第  34.0  页的数据\n",
      "第  35.0  页的数据\n",
      "第  36.0  页的数据\n",
      "第  37.0  页的数据\n",
      "第  38.0  页的数据\n",
      "第  39.0  页的数据\n",
      "第  40.0  页的数据\n",
      "第  41.0  页的数据\n",
      "第  42.0  页的数据\n",
      "第  43.0  页的数据\n",
      "第  44.0  页的数据\n",
      "第  45.0  页的数据\n",
      "第  46.0  页的数据\n",
      "第  47.0  页的数据\n",
      "第  48.0  页的数据\n",
      "第  49.0  页的数据\n",
      "第  50.0  页的数据\n",
      "第  51.0  页的数据\n",
      "第  52.0  页的数据\n",
      "第  53.0  页的数据\n",
      "第  54.0  页的数据\n",
      "第  55.0  页的数据\n",
      "第  56.0  页的数据\n",
      "第  57.0  页的数据\n",
      "第  58.0  页的数据\n",
      "第  59.0  页的数据\n",
      "第  60.0  页的数据\n",
      "第  61.0  页的数据\n",
      "第  62.0  页的数据\n",
      "第  63.0  页的数据\n",
      "第  64.0  页的数据\n",
      "第  65.0  页的数据\n",
      "第  66.0  页的数据\n",
      "第  67.0  页的数据\n",
      "第  68.0  页的数据\n",
      "第  69.0  页的数据\n",
      "第  70.0  页的数据\n",
      "第  71.0  页的数据\n",
      "第  72.0  页的数据\n",
      "第  73.0  页的数据\n",
      "第  74.0  页的数据\n",
      "第  75.0  页的数据\n",
      "第  76.0  页的数据\n",
      "第  77.0  页的数据\n",
      "第  78.0  页的数据\n",
      "第  79.0  页的数据\n",
      "第  80.0  页的数据\n",
      "第  81.0  页的数据\n",
      "第  82.0  页的数据\n",
      "第  83.0  页的数据\n",
      "第  84.0  页的数据\n",
      "[]\n",
      "xlsx格式表格写入数据成功！\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pagenext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
